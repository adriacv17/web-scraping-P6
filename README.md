# Project 6 - Web Scraping and NLP

## Objectives
This exercise is used to practice web scraping (fetching and extracting information) and processing the content from a web page. 

## Task 1. Get Started
1. Copy the base repository into your GitHub account by selecting the "Use this Template" button on GitHub and specifying yourself as the owner.  The base repository is available at: https://github.com/wmnlp-materials/web-scrapingLinks to an external site.
2. Clone YOUR new repo down to your machine.
NOTE: If you already have a project folder on your machine from this repo: https://github.com/denisecase/620-mod6-web-scrapingLinks to an external site. You can just move the notebook from the base repository into that folder and reuse the .venv you're already working on. 

## Task 2. Open Notebook and Complete Tasks 
1. On your machine, open the Jupyter Notebook for editing. 
2. Required: In your Markdown introduction, add a viewable, clickable link to your GitHub repo after your name. Build your brand and make your Markdown introduction clear and professional. 
3. Required: Use Markdown headings  (e.g. Question 1) to clearly show your content by each question number. 
4. Complete the first task.
5. Execute the notebook. Commit and push to GitHub. Verify your notebook appears correctly.
6. Complete the second task.
7. Execute the notebook. Commit and push to GitHub. Verify your notebook appears correctly.
8. Work this way until all tasks have been completed. 
<br>
Add packages as needed if you are missing any. The following - or more - may be required:

* beautifulsoup4
* html5lib
* ipykernel
* jupyterlab
* matplotlib
* requests
* spacy
* spacytextblob

## Task 3. Export to HTML and Finalize Repo
1. Execute each notebook.
2. After executing, export each notebook to HTML.
3. Commit and push your HTML files to your GitHub repo along with the executed notebooks. 
4. Verify you have a professional README.md that introduces your GitHub repository and provides helpful information about your project. 

## Requirements
1. Markdown introduction with name and clickable link is required.
2. Markdown Section Headings for each Question are required. 
3. Execute your code before exporting HTML and pushing notebooks. (See FAQ for help.)  
4. Unexecuted code is not eligible for credit.

# Web Scraping and NLP with Requests, BeautifulSoup, and spaCy

Complete the tasks in the Python Notebook in this repository.
Make sure to add and push the pkl or text file of your scraped html (this is specified in the notebook)

## Rubric

* (Question 1) Article html stored in separate file that is committed and pushed: 1 pt
* (Question 2) Article text is correct: 1 pt
* (Question 3) Correct (or equivalent in the case of multiple tokens with same frequency) tokens printed: 1 pt
* (Question 4) Correct (or equivalent in the case of multiple lemmas with same frequency) lemmas printed: 1 pt
* (Question 5) Correct scores for first sentence printed: 2 pts (1 / function)
* (Question 6) Histogram shown with appropriate labelling: 1 pt
* (Question 7) Histogram shown with appropriate labelling: 1 pt
* (Question 8) Thoughtful answer provided: 1 pt
